{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import Utils\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import pickle\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense, Input, GlobalMaxPooling1D, GlobalAveragePooling1D, Flatten, Dropout\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding, Merge, Reshape\n",
    "from keras.models import Model, load_model\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# import nltk\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import unicodedata\n",
    "import re\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_W2V_model(path):\n",
    "    model = KeyedVectors.load_word2vec_format(path, binary=True)\n",
    "    print(\"Loaded W2V model\")\n",
    "    return model\n",
    "\n",
    "def load_data(path):\n",
    "    df = pd.read_csv(path, sep='\\t', index_col=0)\n",
    "    print(\"Loaded dataset:\", path)\n",
    "    return df\n",
    "\n",
    "def review_to_wordlist(raw_review, stemmer=False):\n",
    "    # Function to convert a raw review to a string of words\n",
    "    # The input is a single string (a raw movie review), and \n",
    "    # the output is a single string (a preprocessed movie review)\n",
    "    #\n",
    "    # 1. Remove accent marks\n",
    "    review_text = ''.join((c for c in unicodedata.normalize('NFD',str(raw_review)) if unicodedata.category(c) != 'Mn'))\n",
    "    #\n",
    "    # 2. Remove non-letters\n",
    "    #letters_only = re.sub(\"[^A-Za-z0-9]\", \" \", review_text) \n",
    "    letters_only = re.sub(\"[^\\w\\d]\", \" \", review_text) \n",
    "    #\n",
    "    # 2. Convert to lower case, split into individual words\n",
    "    words = letters_only.lower().split()                             \n",
    "    #\n",
    "    # 3. In Python, searching a set is much faster than searching\n",
    "    #   a list, so convert the stop words to a set\n",
    "    stops = set(stopwords.words(\"spanish\"))                  \n",
    "    # \n",
    "    # 4. Remove stop words and apply or not stemming\n",
    "    if stemmer:\n",
    "        meaningful_words = [stemmer.stem(w) for w in words if not w in stops]\n",
    "    else:\n",
    "        meaningful_words = [w for w in words if not w in stops]\n",
    "    #\n",
    "    # 5. Join the words back into one string separated by space, \n",
    "    # and return the result.\n",
    "    #return( \" \".join( meaningful_words ))\n",
    "    return meaningful_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded W2V model\n",
      "Loaded dataset: ./hufa_train_stem_skip/train\n",
      "Loaded dataset: ./hufa_test_stem_skip/test\n",
      "Loaded dataset: ./hufa_dev_stem_skip/dev\n"
     ]
    }
   ],
   "source": [
    "path_w2v_hufa = \"./W2V/hufa_stem-300-5w-10n-skip.bin\"\n",
    "path_w2v_wiki = \"./W2V/sbw_vectors.bin\"\n",
    "path_data_train = \"./hufa_train_stem_skip/train\"\n",
    "path_data_test = \"./hufa_test_stem_skip/test\"\n",
    "path_data_dev = \"./hufa_dev_stem_skip/dev\"\n",
    "\n",
    "MAX_NB_WORDS = 20000\n",
    "EMBEDDING_DIM = 300\n",
    "MAX_SEQUENCE_LENGTH = 2000\n",
    "#MAX_SEQUENCE_LENGTH = 2000\n",
    "\n",
    "stemmer = SnowballStemmer('spanish')\n",
    "model = load_W2V_model(path_w2v_hufa)\n",
    "df_train = load_data(path_data_train)\n",
    "df_test = load_data(path_data_test)\n",
    "df_dev = load_data(path_data_dev)\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(131940, 32986, 54976)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train), len(df_dev), len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54473"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_test[df_test.label == False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtrain = [review_to_wordlist(text, stemmer) for text in df_train.text]\n",
    "Ytrain = np.asarray(df_train.label)\n",
    "Xdev = [review_to_wordlist(text, stemmer) for text in df_dev.text]\n",
    "Ydev = np.asarray(df_dev.label)\n",
    "Xtest = [review_to_wordlist(text, stemmer) for text in df_test.text]\n",
    "Ytest = np.asarray(df_test.label)\n",
    "texts = Xtrain+Xdev+Xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/matplotlib/axes/_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA30AAANOCAYAAAClZGW6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1080x1080 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "plt.subplots(figsize=(15,15))\n",
    "sns.set(color_codes=True)\n",
    "x = np.asarray([len(t) for t in texts])\n",
    "sns.distplot(x,);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(texts)\n",
    "\n",
    "sequences_train = tokenizer.texts_to_sequences(Xtrain)\n",
    "sequences_dev = tokenizer.texts_to_sequences(Xdev)\n",
    "sequences_test = tokenizer.texts_to_sequences(Xtest)\n",
    "del Xtrain, Xdev, Xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train 80% - dev 20%\n",
    "mitad = int(len(sequences_train)/2)\n",
    "Xdev = pad_sequences(sequences_dev, maxlen=MAX_SEQUENCE_LENGTH, padding='pre', truncating='pre', dtype='int16')\n",
    "Xtrain = pad_sequences(sequences_train[:mitad], maxlen=MAX_SEQUENCE_LENGTH, padding='pre', truncating='pre', dtype='int16')\n",
    "Xtrain = np.concatenate((Xtrain, pad_sequences(sequences_train[mitad:], maxlen=MAX_SEQUENCE_LENGTH, padding='pre', truncating='pre', dtype='int16')))\n",
    "Xtest = pad_sequences(sequences_test, maxlen=MAX_SEQUENCE_LENGTH, padding='pre', truncating='pre', dtype='int16')\n",
    "del sequences_dev, sequences_train, sequences_test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index\n",
    "num_words = min(MAX_NB_WORDS, len(word_index))\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM), dtype=np.float32)\n",
    "for word, i in word_index.items():\n",
    "    if i >= num_words:\n",
    "        continue\n",
    "    if word in model:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = model[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(num_words,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)\n",
    "\n",
    "# class_W = class_weight.compute_class_weight('balanced', np.unique(np.asarray(df_train.label)), np.asarray(df_train.label))\n",
    "# class_weight_dict = dict(enumerate(class_W))\n",
    "\n",
    "class Metrics(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.f1s = 0\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        predict = np.asarray(np.round(self.model.predict(self.validation_data[0])))\n",
    "        targ = self.validation_data[1]\n",
    "        f1 = f1_score(targ, predict)\n",
    "        print (\"\\nF1 on dev: \"+str(f1)+\"\\n\")\n",
    "        if (self.f1s < f1):\n",
    "            self.f1s = f1\n",
    "            self.model.save('./model/Best_EMRS_model_f1_.hdf5')\n",
    "            print(\"Modelo guardado\\n\")\n",
    "        return\n",
    "    \n",
    "metrics = Metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compile\n"
     ]
    }
   ],
   "source": [
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int16')\n",
    "\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "x = Conv1D(64, 2, activation='relu')(embedded_sequences)\n",
    "x = GlobalMaxPooling1D()(x)\n",
    "y = Conv1D(64, 3, activation='relu')(embedded_sequences)\n",
    "y = GlobalMaxPooling1D()(y)\n",
    "z = Conv1D(64, 5, activation='relu')(embedded_sequences)\n",
    "z = GlobalMaxPooling1D()(z)\n",
    "\n",
    "x = Concatenate()([x,y,z])\n",
    "\n",
    "preds = Dense(1, activation='sigmoid')(x)\n",
    "Conv_model = Model(sequence_input, preds)\n",
    "print('compile')\n",
    "\n",
    "Conv_model.compile(loss='binary_crossentropy',\n",
    "              optimizer='Adam',\n",
    "              metrics=[Utils.precision,Utils.recall,Utils.fmeasure])\n",
    "\n",
    "#filepath=\"./model/weights-improvement.hdf5\"\n",
    "callbacks_list = [metrics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit\n",
      "Train on 131940 samples, validate on 54976 samples\n",
      "Epoch 1/50\n",
      "131940/131940 [==============================] - 2759s 21ms/step - loss: 0.0229 - precision: 0.4822 - recall: 0.4359 - fmeasure: 0.4508 - val_loss: 0.0053 - val_precision: 0.0105 - val_recall: 0.0096 - val_fmeasure: 0.0100\n",
      "\n",
      "F1 on dev: 0.9512953367875647\n",
      "\n",
      "Modelo guardado\n",
      "\n",
      "Epoch 2/50\n",
      "131940/131940 [==============================] - 2650s 20ms/step - loss: 0.0044 - precision: 0.7905 - recall: 0.7484 - fmeasure: 0.7621 - val_loss: 0.0035 - val_precision: 0.0105 - val_recall: 0.0096 - val_fmeasure: 0.0100\n",
      "\n",
      "F1 on dev: 0.9523809523809524\n",
      "\n",
      "Modelo guardado\n",
      "\n",
      "Epoch 3/50\n",
      "131940/131940 [==============================] - 2646s 20ms/step - loss: 0.0032 - precision: 0.7977 - recall: 0.7577 - fmeasure: 0.7704 - val_loss: 0.0031 - val_precision: 0.0105 - val_recall: 0.0097 - val_fmeasure: 0.0100\n",
      "\n",
      "F1 on dev: 0.9557157569515963\n",
      "\n",
      "Modelo guardado\n",
      "\n",
      "Epoch 4/50\n",
      "131940/131940 [==============================] - 2646s 20ms/step - loss: 0.0025 - precision: 0.8258 - recall: 0.7891 - fmeasure: 0.8011 - val_loss: 0.0036 - val_precision: 0.0105 - val_recall: 0.0096 - val_fmeasure: 0.0100\n",
      "\n",
      "F1 on dev: 0.955440414507772\n",
      "\n",
      "Epoch 5/50\n",
      "131940/131940 [==============================] - 2649s 20ms/step - loss: 0.0021 - precision: 0.8149 - recall: 0.7905 - fmeasure: 0.7989 - val_loss: 0.0030 - val_precision: 0.0105 - val_recall: 0.0097 - val_fmeasure: 0.0101\n",
      "\n",
      "F1 on dev: 0.945233265720081\n",
      "\n",
      "Epoch 6/50\n",
      "131940/131940 [==============================] - 2649s 20ms/step - loss: 0.0015 - precision: 0.8177 - recall: 0.7976 - fmeasure: 0.8041 - val_loss: 0.0030 - val_precision: 0.0105 - val_recall: 0.0097 - val_fmeasure: 0.0100\n",
      "\n",
      "F1 on dev: 0.9547325102880659\n",
      "\n",
      "Epoch 7/50\n",
      "131940/131940 [==============================] - 2647s 20ms/step - loss: 0.0011 - precision: 0.8150 - recall: 0.7985 - fmeasure: 0.8041 - val_loss: 0.0031 - val_precision: 0.0105 - val_recall: 0.0096 - val_fmeasure: 0.0100\n",
      "\n",
      "F1 on dev: 0.9536560247167869\n",
      "\n",
      "Epoch 8/50\n",
      "131940/131940 [==============================] - 2646s 20ms/step - loss: 7.6521e-04 - precision: 0.8354 - recall: 0.8251 - fmeasure: 0.8284 - val_loss: 0.0031 - val_precision: 0.0105 - val_recall: 0.0097 - val_fmeasure: 0.0101\n",
      "\n",
      "F1 on dev: 0.9518935516888434\n",
      "\n",
      "Epoch 9/50\n",
      "131940/131940 [==============================] - 2651s 20ms/step - loss: 4.9012e-04 - precision: 0.8446 - recall: 0.8415 - fmeasure: 0.8423 - val_loss: 0.0031 - val_precision: 0.0105 - val_recall: 0.0098 - val_fmeasure: 0.0101\n",
      "\n",
      "F1 on dev: 0.9494949494949495\n",
      "\n",
      "Epoch 10/50\n",
      "131940/131940 [==============================] - 2651s 20ms/step - loss: 2.9728e-04 - precision: 0.8526 - recall: 0.8498 - fmeasure: 0.8507 - val_loss: 0.0035 - val_precision: 0.0105 - val_recall: 0.0096 - val_fmeasure: 0.0100\n",
      "\n",
      "F1 on dev: 0.9537512846865366\n",
      "\n",
      "Epoch 11/50\n",
      "131940/131940 [==============================] - 2652s 20ms/step - loss: 1.6840e-04 - precision: 0.8363 - recall: 0.8363 - fmeasure: 0.8363 - val_loss: 0.0034 - val_precision: 0.0105 - val_recall: 0.0097 - val_fmeasure: 0.0101\n",
      "\n",
      "F1 on dev: 0.952965235173824\n",
      "\n",
      "Epoch 12/50\n",
      "131940/131940 [==============================] - 2651s 20ms/step - loss: 1.2028e-04 - precision: 0.8299 - recall: 0.8302 - fmeasure: 0.8301 - val_loss: 0.0034 - val_precision: 0.0105 - val_recall: 0.0097 - val_fmeasure: 0.0101\n",
      "\n",
      "F1 on dev: 0.9520897043832824\n",
      "\n",
      "Epoch 13/50\n",
      "131940/131940 [==============================] - 2651s 20ms/step - loss: 8.2078e-05 - precision: 0.8514 - recall: 0.8514 - fmeasure: 0.8514 - val_loss: 0.0037 - val_precision: 0.0105 - val_recall: 0.0097 - val_fmeasure: 0.0101\n",
      "\n",
      "F1 on dev: 0.9558067831449126\n",
      "\n",
      "Modelo guardado\n",
      "\n",
      "Epoch 14/50\n",
      "131940/131940 [==============================] - 2651s 20ms/step - loss: 4.6258e-05 - precision: 0.8226 - recall: 0.8226 - fmeasure: 0.8226 - val_loss: 0.0039 - val_precision: 0.0105 - val_recall: 0.0097 - val_fmeasure: 0.0100\n",
      "\n",
      "F1 on dev: 0.9527720739219713\n",
      "\n",
      "Epoch 15/50\n",
      "131940/131940 [==============================] - 2651s 20ms/step - loss: 3.1153e-05 - precision: 0.8393 - recall: 0.8393 - fmeasure: 0.8393 - val_loss: 0.0041 - val_precision: 0.0105 - val_recall: 0.0097 - val_fmeasure: 0.0100\n",
      "\n",
      "F1 on dev: 0.956701030927835\n",
      "\n",
      "Modelo guardado\n",
      "\n",
      "Epoch 16/50\n",
      "131940/131940 [==============================] - 2651s 20ms/step - loss: 2.0464e-05 - precision: 0.8519 - recall: 0.8519 - fmeasure: 0.8519 - val_loss: 0.0044 - val_precision: 0.0105 - val_recall: 0.0097 - val_fmeasure: 0.0100\n",
      "\n",
      "F1 on dev: 0.956701030927835\n",
      "\n",
      "Epoch 17/50\n",
      "131940/131940 [==============================] - 2651s 20ms/step - loss: 1.4528e-05 - precision: 0.8348 - recall: 0.8348 - fmeasure: 0.8348 - val_loss: 0.0047 - val_precision: 0.0105 - val_recall: 0.0097 - val_fmeasure: 0.0100\n",
      "\n",
      "F1 on dev: 0.956701030927835\n",
      "\n",
      "Epoch 18/50\n",
      "131940/131940 [==============================] - 2650s 20ms/step - loss: 1.0740e-05 - precision: 0.8226 - recall: 0.8226 - fmeasure: 0.8226 - val_loss: 0.0043 - val_precision: 0.0105 - val_recall: 0.0097 - val_fmeasure: 0.0101\n",
      "\n",
      "F1 on dev: 0.9538461538461539\n",
      "\n",
      "Epoch 19/50\n",
      "131940/131940 [==============================] - 2651s 20ms/step - loss: 7.5996e-06 - precision: 0.8242 - recall: 0.8242 - fmeasure: 0.8242 - val_loss: 0.0049 - val_precision: 0.0105 - val_recall: 0.0097 - val_fmeasure: 0.0100\n",
      "\n",
      "F1 on dev: 0.956701030927835\n",
      "\n",
      "Epoch 20/50\n",
      "131940/131940 [==============================] - 2651s 20ms/step - loss: 5.4740e-06 - precision: 0.8545 - recall: 0.8545 - fmeasure: 0.8545 - val_loss: 0.0055 - val_precision: 0.0105 - val_recall: 0.0096 - val_fmeasure: 0.0100\n",
      "\n",
      "F1 on dev: 0.9566115702479339\n",
      "\n",
      "Epoch 21/50\n",
      "131940/131940 [==============================] - 2654s 20ms/step - loss: 3.8214e-06 - precision: 0.8398 - recall: 0.8398 - fmeasure: 0.8398 - val_loss: 0.0052 - val_precision: 0.0105 - val_recall: 0.0097 - val_fmeasure: 0.0100\n",
      "\n",
      "F1 on dev: 0.956701030927835\n",
      "\n",
      "Epoch 22/50\n",
      "131940/131940 [==============================] - 2656s 20ms/step - loss: 2.7415e-06 - precision: 0.8439 - recall: 0.8439 - fmeasure: 0.8439 - val_loss: 0.0056 - val_precision: 0.0105 - val_recall: 0.0096 - val_fmeasure: 0.0100\n",
      "\n",
      "F1 on dev: 0.95562435500516\n",
      "\n",
      "Epoch 23/50\n",
      "131940/131940 [==============================] - 2650s 20ms/step - loss: 2.0415e-06 - precision: 0.8443 - recall: 0.8443 - fmeasure: 0.8443 - val_loss: 0.0052 - val_precision: 0.0105 - val_recall: 0.0097 - val_fmeasure: 0.0100\n",
      "\n",
      "F1 on dev: 0.9547325102880659\n",
      "\n",
      "Epoch 24/50\n",
      "131940/131940 [==============================] - 2641s 20ms/step - loss: 1.4971e-06 - precision: 0.8545 - recall: 0.8545 - fmeasure: 0.8545 - val_loss: 0.0058 - val_precision: 0.0105 - val_recall: 0.0097 - val_fmeasure: 0.0100\n",
      "\n",
      "F1 on dev: 0.956701030927835\n",
      "\n",
      "Epoch 25/50\n",
      "131940/131940 [==============================] - 2642s 20ms/step - loss: 1.0566e-06 - precision: 0.8333 - recall: 0.8333 - fmeasure: 0.8333 - val_loss: 0.0056 - val_precision: 0.0105 - val_recall: 0.0097 - val_fmeasure: 0.0100\n",
      "\n",
      "F1 on dev: 0.956701030927835\n",
      "\n",
      "Epoch 26/50\n",
      "131940/131940 [==============================] - 2644s 20ms/step - loss: 7.8290e-07 - precision: 0.8302 - recall: 0.8302 - fmeasure: 0.8302 - val_loss: 0.0057 - val_precision: 0.0105 - val_recall: 0.0097 - val_fmeasure: 0.0100\n",
      "\n",
      "F1 on dev: 0.956701030927835\n",
      "\n",
      "Epoch 27/50\n",
      "131940/131940 [==============================] - 2662s 20ms/step - loss: 6.0284e-07 - precision: 0.8211 - recall: 0.8211 - fmeasure: 0.8211 - val_loss: 0.0060 - val_precision: 0.0105 - val_recall: 0.0097 - val_fmeasure: 0.0100\n",
      "\n",
      "F1 on dev: 0.956701030927835\n",
      "\n",
      "Epoch 28/50\n",
      "123800/131940 [===========================>..] - ETA: 2:24 - loss: 4.7793e-07 - precision: 0.8320 - recall: 0.8320 - fmeasure: 0.8320"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-8b5e6340f094>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m       \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m       \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m       validation_data=(Xtest, Ytest))\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1310\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1312\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1418\u001b[0m         return tf_session.TF_Run(\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print('fit')\n",
    "Conv_model.fit(Xtrain, Ytrain,\n",
    "      #class_weight=class_weight_dict,\n",
    "      shuffle=True,\n",
    "      batch_size=200,\n",
    "      epochs=50,\n",
    "      callbacks=callbacks_list,\n",
    "      validation_data=(Xtest, Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Best_model = load_model('./model/Best_EMRS_model_f1.hdf5', custom_objects={'precision': Utils.precision, 'recall':Utils.recall, 'fmeasure':Utils.fmeasure})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False     0.9993    0.9999    0.9996     54473\n",
      "       True     0.9894    0.9264    0.9569       503\n",
      "\n",
      "avg / total     0.9992    0.9992    0.9992     54976\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = np.round(Best_model.predict(Xtest))\n",
    "print(classification_report(Ytest, result, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2769"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del Conv_model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 2000)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 2000, 300)    6000000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 1999, 64)     38464       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 1998, 64)     57664       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 1996, 64)     96064       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 64)           0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_2 (GlobalM (None, 64)           0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_3 (GlobalM (None, 64)           0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 192)          0           global_max_pooling1d_1[0][0]     \n",
      "                                                                 global_max_pooling1d_2[0][0]     \n",
      "                                                                 global_max_pooling1d_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            193         concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 6,192,385\n",
      "Trainable params: 192,385\n",
      "Non-trainable params: 6,000,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Best_model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
